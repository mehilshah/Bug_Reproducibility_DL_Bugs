2023-07-01 11:33:00.165259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
C:\Users\XYZ\Downloads\Bug Reproducibility\venv\lib\site-packages\keras\optimizers\optimizer_v2\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)
Epoch 1/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 1s 530ms/step - loss: 0.6667
Epoch 2/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 3/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 16ms/step - loss: 0.6667
Epoch 4/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 5/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 6/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 7/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 8/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 8ms/step - loss: 0.6667
Epoch 9/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 10/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 8ms/step - loss: 0.6667
Epoch 11/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 12/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 13/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 14/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 8ms/step - loss: 0.6667
Epoch 15/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 16/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 17/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 18/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 8ms/step - loss: 0.6667
Epoch 19/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667
Epoch 20/20

1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 0s/step - loss: 0.6667


1/1 [==============================] - ETA: 0s - loss: 0.6667
1/1 [==============================] - 0s 186ms/step - loss: 0.6667

0.6666666865348816

1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 109ms/step
[[1.]]

1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 32ms/step
[[1.]]
