Type of Bug,Bug ID,Code,Text
API Bug,71223747,"import torch a1, a2 = torch.tensor([1,2], dtype = torch.float64) b = torch.rand(2, requires_grad = True) a1 += b.sum() RuntimeError: A view was created in no_grad mode and is being modified inplace with grad mode enabled. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one. a1 = torch.tensor([1], dtype = torch.float64) a1 += b.sum()","I have an error when modifying an unpacked tensor. This code produces the following error: However, I didn't receive that error when I created a1 and a2 separately as follows: I have no idea why unpacking a tensor would lead to that error. Any help is greatly appreciated"
API Bug,61706535,"train_test_split() model.fit(X_train, y_train, validation_data=[X_val, y_val])","I am trying to train a simple 2 layer Fully Connected neural net for Binary Classification in Tensorflow keras. I have split my data into Training and Validation sets with a 80-20 split using sklearn's . When I call , it shows 0 validation loss and accuracy for all epochs, but it trains just fine. Also, when I try to evaluate it on the validation set, the output is non-zero. Can someone please explain why I am facing this 0 loss 0 accuracy error on validation. Thanks for your help. Here is the complete sample code (MCVE) for this error: https://colab.research.google.com/drive/1P8iCUlnD87vqtuS5YTdoePcDOVEKpBHr?usp=sharing"
API Bug,50920908,"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(X_test, y_test)) # starts training X_test Out[25]: array([[621, 139, 549, ..., 0, 0, 0], [621, 139, 543, ..., 0, 0, 0]]) y_test Out[26]: array([[0, 0, 1], [0, 1, 0]]) predictions = model.predict(X_test) predictions Out[27]: array([[ 0.29071924, 0.2483743 , 0.46090645], [ 0.29566404, 0.45295066, 0.25138539]], dtype=float32) y_pred = (predictions &gt; 0.5) confusion_matrix(y_test, y_pred) Traceback (most recent call last): File ""&lt;ipython-input-38-430e012b2078&gt;"", line 1, in &lt;module&gt; confusion_matrix(y_test, y_pred) File ""/Users/abrahammathew/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py"", line 252, in confusion_matrix raise ValueError(""%s is not supported"" % y_type) ValueError: multilabel-indicator is not supported","I am building a multiclass model with Keras. Here is how my test data looks like (it's text data). After generating predictions... I did the following to get the confusion matrix. However, I am getting the above error. How can I get a confusion matrix when doing a multiclass neural network in Keras?"
API Bug,69137834,"x_train : float32 0.0 1.0 (2444, 64, 64, 1) y_train : float32 0.0 1.0 (2444, 2) x_test : float32 0.0 1.0 (9123, 64, 64, 1) y_test : float32 0.0 1.0 (9123, 2) inputs = keras.Input(shape=(64,64,1), dtype='float32') x = keras.layers.Conv2D(12,(9,9), padding=&quot;same&quot;,input_shape=(64,64,1), dtype='float32',activation='relu')(inputs) x = keras.layers.Conv2D(18,(7,7), padding=&quot;same&quot;, activation='relu')(x) x = keras.layers.MaxPool2D(pool_size=(2,2))(x) x = keras.layers.Dropout(0.25)(x) x = keras.layers.Dense(50, activation='relu')(x) x = keras.layers.Dropout(0.4)(x) outputs = keras.layers.Dense(2, activation='softmax')(x) model = keras.Model(inputs, outputs) Model: &quot;model_1&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) [(None, 64, 64, 1)] 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 64, 64, 12) 984 _________________________________________________________________ conv2d_3 (Conv2D) (None, 64, 64, 18) 10602 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 32, 32, 18) 0 _________________________________________________________________ dropout_2 (Dropout) (None, 32, 32, 18) 0 _________________________________________________________________ dense_2 (Dense) (None, 32, 32, 50) 950 _________________________________________________________________ dropout_3 (Dropout) (None, 32, 32, 50) 0 _________________________________________________________________ dense_3 (Dense) (None, 32, 32, 2) 102 ================================================================= Total params: 12,638 Trainable params: 12,638 Non-trainable params: 0 ________________________ model.compile( loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(0.01), metrics=[&quot;acc&quot;], ) model.fit(x_train, y_train, batch_size=32, epochs = 20, validation_split= 0.3, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]) ValueError Traceback (most recent call last) &lt;ipython-input-31-e4cade46a08c&gt; in &lt;module&gt;() 1 model.fit(x_train, y_train, batch_size=32, epochs = 20, validation_split= 0.3, ----&gt; 2 callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]) 9 frames /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs) 992 except Exception as e: # pylint:disable=broad-except 993 if hasattr(e, &quot;ag_error_metadata&quot;): --&gt; 994 raise e.ag_error_metadata.to_exception(e) 995 else: 996 raise ValueError: in user code: /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function * return step_function(self, iterator) /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function ** outputs = model.distribute_strategy.run(run_step, args=(data,)) /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs) /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica return self._call_for_each_replica(fn, args, kwargs) /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica return fn(*args, **kwargs) /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step ** outputs = model.train_step(data) /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:792 train_step self.compiled_metrics.update_state(y, y_pred, sample_weight) /usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py:457 update_state metric_obj.update_state(y_t, y_p, sample_weight=mask) /usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py:73 decorated update_op = update_state_fn(*args, **kwargs) /usr/local/lib/python3.7/dist-packages/keras/metrics.py:177 update_state_fn return ag_update_state(*args, **kwargs) /usr/local/lib/python3.7/dist-packages/keras/metrics.py:681 update_state ** matches = ag_fn(y_true, y_pred, **self._fn_kwargs) /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper return target(*args, **kwargs) /usr/local/lib/python3.7/dist-packages/keras/metrics.py:3537 sparse_categorical_accuracy return tf.cast(tf.equal(y_true, y_pred), backend.floatx()) /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper return target(*args, **kwargs) /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1864 equal return gen_math_ops.equal(x, y, name=name) /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:3219 equal name=name) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper attrs=attr_protos, op_def=op_def) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal compute_device) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal op_def=op_def) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:2042 __init__ control_input_ops, op_def) /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1883 _create_c_op raise ValueError(str(e)) ValueError: Dimensions must be equal, but are 2 and 32 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](IteratorGetNext:1, Cast_1)' with input shapes: [?,2], [?,32,32].",I was trying to train a simple Keras network for classification when I faced the following error. I know there is something wrong with my inputs but I couldn't figure out how to fix it. Here is my code my data set shape : the model : model summary : compiler and fitter which error occurs when I wanna fit the model and finally the error:
API Bug,66489112,"TypeError: __init__() got an unexpected keyword argument 'filepath' File &quot;train.py&quot;, line 167, in &lt;module&gt; main(args) File &quot;train.py&quot;, line 113, in main checkpoint_callback=checkpoint_callback(), File &quot;train.py&quot;, line 86, in checkpoint_callback return ModelCheckpoint( TypeError: __init__() got an unexpected keyword argument 'filepath' from pytorch_lightning.callbacks import ModelCheckpoint save_model_path = path/to/your/dir def checkpoint_callback(): return ModelCheckpoint( filepath= save_model_path, save_top_k=True, verbose=True, monitor='val_loss', mode='min', prefix='' )",I don't know how to solve this error but I hope some of you guys know how to solve this issue. Error: Full error message:
API Bug,65889068,"#Import Libraries from keras.models import Sequential from keras.layers import Dense, Conv2D, MaxPool2D , Flatten from keras.optimizers import SGD #model details vgg19 = Sequential() vgg19.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(Conv2D(filters=64,kernel_size=(3,3),padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2))) vgg19.add(Conv2D(filters=128, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(Conv2D(filters=128, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2))) vgg19.add(Conv2D(filters=256, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(Conv2D(filters=256, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(Conv2D(filters=256, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2))) vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2))) vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding=&quot;same&quot;, activation=&quot;relu&quot;)) vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2))) vgg19.add(Flatten()) vgg19.add(Dense(units=4096,activation=&quot;relu&quot;)) vgg19.add(Dense(units=4096,activation=&quot;relu&quot;)) vgg19.add(Dense(units=10, activation=&quot;softmax&quot;)) #Preparing Dataset from keras.datasets import cifar10 from keras.utils import to_categorical (X, Y), (tsX, tsY) = cifar10.load_data() # Use a one-hot-encoding Y = to_categorical(Y) tsY = to_categorical(tsY) # Change datatype to float X = X.astype('float32') tsX = tsX.astype('float32') # Scale X and tsX so each entry is between 0 and 1 X = X / 255.0 tsX = tsX / 255.0 #training optimizer = SGD(lr=0.001, momentum=0.9) vgg19.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) history = vgg19.fit(X, Y, epochs=100, batch_size=64, validation_data=(tsX, tsY), verbose=0) value error ValueError: Input 0 of layer dense_9 is incompatible with the layer: expected axis -1 of input shape to have value 25088 but received input with shape (None, 512)","I am trying to run the Keras tutorial mentioned below in python: Upon training the model, I am getting the below mentioned : Please suggest, how to fix the input shape and would be better if someone can provide a brief explanation of the issue. Thanks in advance!"
API Bug,64576751,"Price Beds SqFt Built Garage FullBaths HalfBaths LotSqFt 485000 3 2336 2004 2 2.0 1.0 2178.0 430000 4 2106 2005 2 2.0 1.0 2178.0 445000 3 1410 1999 1 2.0 0.0 3049.0 ... TypeError: unsupported operand type(s) for +=: 'Dense' and 'str' print(df.dtypes) ## Output #Price int64 #Beds int64 #SqFt int64 #Built int64 #Garage int64 #FullBaths float64 #HalfBaths float64 #LotSqFt float64 #dtype: object dataset = df.values X = dataset[:, 1:8] Y = dataset[:,0] ## Normalize X-Values from sklearn import preprocessing min_max_scaler = preprocessing.MinMaxScaler() X_scale = min_max_scaler.fit_transform(X) X_scale ##Partition Data from sklearn.model_selection import train_test_split X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3) X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5) print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape) from keras.models import Sequential from keras.layers import Dense model = Sequential( Dense(32, activation='relu', input_shape=(7,)), Dense(1, activation='linear')) model.compile(optimizer='sgd', loss='mse', metrics=['mean_squared_error']) model.evaluate(X_test, Y_test)[1] ##Type Error is here!","I am trying to use a neural network to predict the price of houses. Here is what the top of the dataset looks like: I am using the ReLU activation function. When I try to evaluate my model on my test data, I get this . I looked at the types of the columns from my original dataframe, and everything looks fine. I'm not sure if I am messing something up in my neural network to cause this error. Any help is appreciated! Here is my code for reference. Prepare Data for Network Begin Model Building"
API Bug,55142951,"sess = tf.Session() Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; AttributeError: module 'tensorflow' has no attribute 'Session'","When I am executing the command in Tensorflow 2.0 environment, I am getting an error message as below: System Information: OS Platform and Distribution: Windows 10 Python Version: 3.7.1 Tensorflow Version: 2.0.0-alpha0 (installed with pip) Steps to reproduce: Installation: pip install --upgrade pip pip install tensorflow==2.0.0-alpha0 pip install keras pip install numpy==1.16.2 Execution: Execute command: import tensorflow as tf Execute command: sess = tf.Session()"
API Bug,68011125,"TypeError: forward() takes 2 positional arguments but 4 were given. class DenseLayer(nn.Module): def __init__(self, in_size, out_size, drop_rate=0.0): super(DenseLayer, self).__init__() self.bottleneck = nn.Sequential() # define bottleneck layers self.bottleneck.add_module('btch1', nn.BatchNorm2d(in_size)) self.bottleneck.add_module('relu1', nn.ReLU(inplace=True)) self.bottleneck.add_module('conv1', nn.ConvTranspose2d(in_size, int(out_size/4), kernel_size=1, stride=1, padding=0, bias=False)) self.basic = nn.Sequential() # define basic block self.basic.add_module('btch2', nn.BatchNorm2d(int(out_size/4))) self.basic.add_module('relu2', nn.ReLU(inplace=True)) self.basic.add_module('conv2', nn.ConvTranspose2d(int(out_size/4), out_size, kernel_size=3, stride=1, padding=1, bias=False)) self.droprate = drop_rate def forward(self, input): out = self.bottleneck(input) if self.droprate &gt; 0: out = F.dropout(out, p=self.droprate, inplace=False, training=self.training) out = self.basic(out) if self.droprate &gt; 0: out = F.dropout(out, p=self.droprate, inplace=False, training=self.training) return torch.cat((x,out), 1) class DenseBlock(nn.Module): def __init__(self, num_layers, in_size, growth_rate, block, droprate=0.0): super(DenseBlock, self).__init__() self.layer = self._make_layer(block, in_size, growth_rate, num_layers, droprate) def _make_layer(self, block, in_size, growth_rate, num_layers, droprate): layers = [] for i in range(num_layers): layers.append(block(in_size, in_size-i*growth_rate, droprate)) return nn.Sequential(*layers) def forward(self, input): return self.layer(input) class MGenDenseNet(nn.Module): def __init__(self, ngpu, growth_rate=32, block_config=(16,24,12,6), in_size=1024, drop_rate=0.0): super(MGenDenseNet, self).__init__() self.ngpu = ngpu self.features = nn.Sequential() self.features.add_module('btch0', nn.BatchNorm2d(in_size)) block = DenseLayer num_features = in_size for i, num_layers in enumerate(block_config): block = DenseBlock(num_layers=num_layers, in_size=num_features, growth_rate=growth_rate, block=block, droprate=drop_rate) ### Error thrown on this line self.features.add_module('denseblock{}'.format(i+1), block) num_features -= num_layers*growth_rate if i!=len(block_config)-1: trans = TransitionLayer(in_size=num_features, out_size=num_features*2, drop_rate=drop_rate) self.features.add_module('transitionblock{}'.format(i+1), trans) num_features *= 2 self.features.add_module('convfinal', nn.ConvTranspose2d(num_features, 3, kernel_size=7, stride=2, padding=3, bias=False)) self.features.add_module('Tanh', nn.Tanh()) def forward(self, input): return self.features(input) mGen = MGenDenseNet(ngpu).to(device) mGen.apply(weights_init) print(mGen)",I am trying to write a GAN generator based on Densenet and Deconv method. I am new to PyTorch and unable to figure out I tried the approach as suggested in Pytorch TypeError: forward() takes 2 positional arguments but 4 were given but I cannot figure out the solution. My code:
API Bug,66524542,"bert_model = BertModel.from_pretrained(r'downloads\bert-pretrained-model') input_ids tensor([[ 101, 156, 13329, ..., 0, 0, 0], [ 101, 156, 13329, ..., 0, 0, 0], [ 101, 1302, 1251, ..., 0, 0, 0], ..., [ 101, 25456, 1200, ..., 0, 0, 0], [ 101, 143, 9664, ..., 0, 0, 0], [ 101, 2586, 7340, ..., 0, 0, 0]]) last_hidden_state, pooled_output = bert_model( input_ids=encoding['input_ids'], attention_mask=encoding['attention_mask'] ) last_hidden_state.shape AttributeError Traceback (most recent call last) &lt;ipython-input-70-9628339f425d&gt; in &lt;module&gt; ----&gt; 1 last_hidden_state.shape AttributeError: 'str' object has no attribute 'shape'",AttributeError: 'str' object has no attribute 'shape' while encoding tensor using BertModel with PyTorch (Hugging Face). Below is the code Output is: Followed by code below Followed by code below Output is Complete Code link is 'https://colab.research.google.com/drive/1FY4WtqCi2CQ9RjHj4slZwtdMhwaWv2-2?usp=sharing'
Model Bug,63073170,"train_image_generator = ImageDataGenerator(rescale=1./255) validation_image_generator = ImageDataGenerator(rescale=1./255) test_image_generator = ImageDataGenerator(rescale=1./255) train_data_gen = train_image_generator.flow_from_directory( train_dir, target_size=(150, 150), batch_size=batch_size, class_mode='binary') val_data_gen =validation_image_generator.flow_from_directory( validation_dir, target_size=(150, 150), batch_size=batch_size, class_mode='binary') test_data_gen = test_image_generator.flow_from_directory( test_dir, target_size=(150, 150), batch_size=batch_size, class_mode='binary', shuffle = False,) !ls /root/.keras/datasets/cats_and_dogs/test 10.jpg 15.jpg 1.jpg 24.jpg 29.jpg 33.jpg 38.jpg 42.jpg 47.jpg 5.jpg 11.jpg 16.jpg 20.jpg 25.jpg 2.jpg 34.jpg 39.jpg 43.jpg 48.jpg 6.jpg 12.jpg 17.jpg 21.jpg 26.jpg 30.jpg 35.jpg 3.jpg 44.jpg 49.jpg 7.jpg 13.jpg 18.jpg 22.jpg 27.jpg 31.jpg 36.jpg 40.jpg 45.jpg 4.jpg 8.jpg 14.jpg 19.jpg 23.jpg 28.jpg 32.jpg 37.jpg 41.jpg 46.jpg 50.jpg 9.jpg",This is my flow_from_directory code And it prints: Found 2000 images belonging to 2 classes. Found 1000 images belonging to 2 classes. Found 0 images belonging to 0 classes. Even though the data exists as I used: Which gives the output: what am I doing wrong or what must be Done?
Model Bug,65228352,"import numpy as np from tensorflow.keras import Sequential from tensorflow.keras.layers import Dense def generator(nb_samples, matrix_size = 2, entries_range = (0,1), determinant = None): ''' Generate nb_samples random matrices of size matrix_size with float entries in interval entries_range and of determinant determinant ''' matrices = [] if determinant: inverses = [] for i in range(nb_samples): matrix = np.random.uniform(entries_range[0], entries_range[1], (matrix_size,matrix_size)) matrix[0] *= determinant/np.linalg.det(matrix) matrices.append(matrix.reshape(matrix_size**2,)) inverses.append(np.array(np.linalg.inv(matrix)).reshape(matrix_size**2,)) return np.array(matrices), np.array(inverses) else: determinants = [] for i in range(nb_samples): matrix = np.random.uniform(entries_range[0], entries_range[1], (matrix_size,matrix_size)) determinants.append(np.array(np.linalg.det(matrix)).reshape(1,)) matrices.append(matrix.reshape(matrix_size**2,)) return np.array(matrices), np.array(determinants) ### Select number of samples, matrix size and range of entries in matrices nb_samples = 10000 matrix_size = 3 entries_range = (0, 100) determinant = 1 ### Generate random matrices and determinants matrices, inverses = generator(nb_samples, matrix_size = matrix_size, entries_range = entries_range, determinant = determinant) ### Select number of layers and neurons nb_hidden_layers = 1 nb_neurons = matrix_size**2 activation = 'relu' ### Create dense neural network with nb_hidden_layers hidden layers having nb_neurons neurons each model = Sequential() model.add(Dense(nb_neurons, input_dim = matrix_size**2, activation = activation)) for i in range(nb_hidden_layers): model.add(Dense(nb_neurons, activation = activation)) model.add(Dense(matrix_size**2)) model.compile(loss='mse', optimizer='adam') ### Train and save model using train size of 0.66 history = model.fit(matrices, inverses, epochs = 400, batch_size = 100, verbose = 0, validation_split = 0.33) ### Get validation loss from object 'history' rmse = np.sqrt(history.history['val_loss'][-1]) ### Print RMSE and parameter values print(''' Validation RMSE: {} Number of hidden layers: {} Number of neurons: {} Number of samples: {} Matrices size: {} Range of entries: {} Determinant: {} '''.format(rmse,nb_hidden_layers,nb_neurons,nb_samples,matrix_size,entries_range,determinant))","I am training a neural network to calculate the inverse of a 3x3 matrix. I am using a Keras dense model with 1 layer and 9 neurons. The activation function on the first layer is 'relu' and linear on the output layer. I am using 10000 matrices of determinant 1. The results I am getting are not very good (RMSE is in the hundreds). I have been trying more layers, more neurons, and other activation functions, but the gain is very small. Here is the code: I have checked online and there seem to be papers dealing with the problem of inverse matrix approximation. However, before changing the model I would like to know if there would be other parameters I could change that could have a bigger impact on the error. I hope someone can provide some insight. Thank you."
Model Bug,63206710,"def create_model(): inp = Input(shape=(561,)) x = Dense(units=1024,input_dim=561)(inp) x = LeakyReLU(0.2)(x) x = Dropout(0.3)(x) x = Dense(units=512)(x) x = LeakyReLU(0.2)(x) x = Dropout(0.3)(x) x = Dense(units=256)(x) x = LeakyReLU(0.2)(x) x = Dense(units=1, activation='sigmoid')(x) m = tf.convert_to_tensor(5) #creating a tensor of value = 5 o = Multiply()([x, m]) #trying to multiply x with o. Doesn't work though! model = Model(inputs=[inp], outputs=[o]) model.compile(loss='binary_crossentropy', optimizer = Adam(lr=0.0002, beta_1=0.5)) return model model = create_model() model.summary()","Pardon me if this is a poorly framed question. This happens to be my first question here. Say I have an output layer in Keras, and I want to multiply the last value (result of sigmoid activation) with a scalar (say 5). (I have attached a code snippet here. Assume all necessary libraries / dependencies included) I tried this, and I am getting &quot;tuple index out of range&quot; error. I would be glad if someone could help me (i.e in multiplication of last layer's output with a scalar)"
Model Bug,72845812,"import torch from transformers import BertTokenizer, BertModel tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') cls_token_id = tokenizer.cls_token_id sep_token_id = tokenizer.sep_token_id pad_token_id = tokenizer.pad_token_id model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True) model.eval() Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias'] - This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). BertModel( (embeddings): BertEmbeddings( (word_embeddings): Embedding(30522, 768, padding_idx=0) (position_embeddings): Embedding(512, 768) (token_type_embeddings): Embedding(2, 768) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) (encoder): BertEncoder( (layer): ModuleList( (0): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (1): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (2): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (3): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (4): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (5): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (6): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (7): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (8): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (9): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (10): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (11): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) (intermediate_act_fn): GELUActivation() ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) ) ) (pooler): BertPooler( (dense): Linear(in_features=768, out_features=768, bias=True) (activation): Tanh() ) ) def text_to_input(text): x = tokenizer.encode(text, add_special_tokens=False) # returns python list x = [cls_token_id] + x + [sep_token_id] token_count = len(x) pad_count = 512 - token_count x = x + [pad_token_id for i in range(pad_count)] return torch.tensor([x]) extract_embeddings = torch.nn.Sequential(list(model.children())[0]) rest_of_bert = torch.nn.Sequential(*list(model.children())[1:]) input_ids = text_to_input('A sentence.') x_embedding = extract_embeddings(input_ids) output = rest_of_bert(x_embedding) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-5-d371d8a2fb3c&gt; in &lt;module&gt;() 12 input_ids = text_to_input('A sentence.') 13 x_embedding = extract_embeddings(input_ids) ---&gt; 14 output = rest_of_bert(x_embedding) 4 frames /usr/local/lib/python3.7/dist-packages/transformers/utils/generic.py in __getitem__(self, k) 220 return inner_dict[k] 221 else: --&gt; 222 return self.to_tuple()[k] 223 224 def __setattr__(self, name, value): TypeError: tuple indices must be integers or slices, not tuple","I want to see embeddings for the input text I give to the model, and then feed it to the rest of the BERT. To do so, I partitioned the model into two sequential models, but I must have done it wrong because rest_of_bert model raises TypeError. Original model does not raise any error with the input_ids as input processed with text_to_input function. Input[0]: Output[0]: Input[1]: Output[1]:"
Model Bug,45711636,"c_X = open(""C:/Users/PC/Desktop/Notebooks/Isabelle/mfcc_train_I_C_I_C_2.dat"", ""r"") c_y = open(""C:/Users/PC/Desktop/Notebooks/Isabelle/phoneme_train_I_C_I_C_2.dat"", ""r"") c_X = np.fromfile(c_X, np.dtype('float32')) c_y = np.fromfile(c_y, np.dtype('int8')) c_X = c_X.reshape(886887,1120) c_X = c_X.reshape(c_X.shape[0], 1, 20, 56) c_y = one_hot(c_y) #c_y = np.append(c_y, np.zeros((374975,1)), axis=1) X_3 = apendice(Colere_X, c_X) y_3 = apendice(Colere_y, c_y) #print(c_X.shape, c_y.shape) print(X_3.shape, y_3.shape) (1123867, 1, 20, 56) (1123867, 38) model = Sequential() model.add(Conv2D(32, (3, 3), border_mode='valid', activation='relu',input_shape=(1, 20, 56))) model.add(Dropout(0.25)) model.add(Conv2D(32, (3, 3), border_mode='valid', activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Conv2D(32, (3, 3), border_mode='valid', activation='relu')) model.add(Conv2D(32, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(1024, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) # Compile the model model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Train the model start = time.time() model_info = model.fit(X_3, y_3, batch_size=100, \ epochs=20, verbose=2, validation_data=(X_test, y_test)) end = time.time() _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_21 (Conv2D) (None, -1, 18, 32) 16160 _________________________________________________________________ dropout_16 (Dropout) (None, -1, 18, 32) 0 _________________________________________________________________ conv2d_22 (Conv2D) (None, -3, 16, 32) 9248 _________________________________________________________________ max_pooling2d_11 (MaxPooling (None, -2, 8, 32) 0 _________________________________________________________________ dropout_17 (Dropout) (None, -2, 8, 32) 0 _________________________________________________________________ conv2d_23 (Conv2D) (None, -4, 6, 32) 9248 _________________________________________________________________ conv2d_24 (Conv2D) (None, -6, 4, 32) 9248 _________________________________________________________________ max_pooling2d_12 (MaxPooling (None, -3, 2, 32) 0 _________________________________________________________________ dropout_18 (Dropout) (None, -3, 2, 32) 0 _________________________________________________________________ flatten_6 (Flatten) (None, -192) 0 ================================================================= Total params: 43,904 Trainable params: 43,904 Non-trainable params: 0 _________________________________________________________________ --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-17-589407073ff5&gt; in &lt;module&gt;() 13 model.add(Flatten()) 14 model.summary() ---&gt; 15 model.add(Dense(256, activation='relu')) 16 model.add(Dropout(0.5)) 17 model.add(Dense(num_classes, activation='softmax')) ~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\keras\models.py in add(self, layer) 467 output_shapes=[self.outputs[0]._keras_shape]) 468 else: --&gt; 469 output_tensor = layer(self.outputs[0]) 470 if isinstance(output_tensor, list): 471 raise TypeError('All layers in a Sequential model ' ~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\keras\engine\topology.py in __call__(self, inputs, **kwargs) 567 '`layer.build(batch_input_shape)`') 568 if len(input_shapes) == 1: --&gt; 569 self.build(input_shapes[0]) 570 else: 571 self.build(input_shapes) ~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\keras\layers\core.py in build(self, input_shape) 823 name='kernel', 824 regularizer=self.kernel_regularizer, --&gt; 825 constraint=self.kernel_constraint) 826 if self.use_bias: 827 self.bias = self.add_weight(shape=(self.units,), ~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\keras\legacy\interfaces.py in wrapper(*args, **kwargs) 85 warnings.warn('Update your `' + object_name + 86 '` call to the Keras 2 API: ' + signature, stacklevel=2) ---&gt; 87 return func(*args, **kwargs) 88 wrapper._original_function = func 89 return wrapper ~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\keras\engine\topology.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint) 389 if dtype is None: 390 dtype = K.floatx() --&gt; 391 weight = K.variable(initializer(shape), dtype=dtype, name=name) 392 if regularizer is not None: 393 self.add_loss(regularizer(weight)) ~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\keras\initializers.py in __call__(self, shape, dtype) 206 limit = np.sqrt(3. * scale) 207 return K.random_uniform(shape, -limit, limit, --&gt; 208 dtype=dtype, seed=self.seed) 209 210 def get_config(self): ~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\keras\backend\theano_backend.py in random_uniform(shape, minval, maxval, dtype, seed) 2189 seed = np.random.randint(1, 10e6) 2190 rng = RandomStreams(seed=seed) -&gt; 2191 return rng.uniform(shape, low=minval, high=maxval, dtype=dtype) 2192 2193 ~\Anaconda3\envs\tensorflow-gpu\lib\site-packages\theano\sandbox\rng_mrg.py in uniform(self, size, low, high, ndim, dtype, nstreams) 854 raise ValueError( 855 ""The specified size contains a dimension with value &lt;= 0"", --&gt; 856 size) 857 858 else: ValueError: ('The specified size contains a dimension with value &lt;= 0', (-192, 256))","I'm trying to build a dcnn, but I got this error: ValueError: ('The specified size contains a dimension with value &lt;= 0', (-192, 1024)) And really, I don't have idea the reason of this error, here's my code: The data: This is my neural network implementation (the problem is here I think): Here the summary of model: I will appreciate your help. Thanks in advance."
Model Bug,73349963,"def Iris_Reader(dataset): train_data, test_data, train_label, test_label = train_test_split(dataset.data, dataset.target, test_size=0.4) # scaler = StandardScaler() # train_data = scaler.fit_transform(train_data) # test_data = scaler.transform(test_data) return torch.FloatTensor(train_data), torch.LongTensor(train_label), torch.FloatTensor(test_data), torch.LongTensor(test_label) class Classifier(nn.Module): def __init__(self): super().__init__() #4*3*3 network self.model = nn.Sequential( nn.Linear(4,3), nn.ReLU(), nn.Linear(3,3), ) #SGD self.optimiser = torch.optim.SGD(self.parameters(), lr = 0.1) #MSE LOSS_FUNCTION self.loss_fn = nn.CrossEntropyLoss() self.counter = 0 self.progress = [] def forward(self, input): return self.model(input) def train(self, input, target): output = self.forward(input) loss = self.loss_fn(output, target) self.counter += 1 self.progress.append(loss.item()) self.optimiser.zero_grad() loss.backward() self.optimiser.step() # plot loss def plot_loss(self): plt.figure(dpi=100) plt.ylim([0,1.0]) plt.yticks([0, 0.25, 0.5, 1.0]) plt.scatter(x = [i for i in range(len(self.progress))], y = self.progress, marker = '.', alpha = 0.2) plt.grid('on') plt.show() C = Classifier() epochs = 10 dataset = datasets.load_iris() for epoch in range(epochs): train_data, train_label, _, _ = Iris_Reader(dataset) for i, j in zip(train_data, train_label): C.train(i, j) score = 0 num = 0 # for epoch in range(epochs): _, _, test_data, test_label = Iris_Reader(dataset) for i,j in zip(test_data, test_label): output = C.forward(i).detach().argmax() if output == j: # print(C.forward(i).detach(), j) score += 1 num += 1 print(score, num, round(score/num, 3))","I have tried many improvements like increasing epochs, using better loss functions and optimizers, deepening the network and shuffling the dataset, etc, but still to no avail. This problem has been bothering me for a long time, thanks for your help. Below is my code. load and process dataset(updated) Define the classifier TRAIN TEST OUTPUT: 53 60 0.883"
Model Bug,74610068,"import numpy as np import tensorflow as tf from keras import layers as tfl class Encoder(tfl.Layer): def __init__(self,): super().__init__() self.embed_layer = tfl.Embedding(4500, 64, mask_zero=True) self.attn_layer = tfl.MultiHeadAttention(num_heads=2, attention_axes=2, key_dim=16) return def call(self, x): # Input shape: (4, 5, 20) (Batch size: 4) x = self.embed_layer(x) # Output: (4, 5, 20, 64) x = self.attn_layer(query=x, key=x, value=x) # Output: (4, 5, 20, 64) return x eg_input = tf.constant(np.random.randint(0, 150, (4, 5, 20))) enc = Encoder() enc(eg_input) {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [4,5,2,20,20] vs. [4,5,1,5,20] [Op:AddV2] Call arguments received by layer 'softmax_2' (type Softmax): • inputs=tf.Tensor(shape=(4, 5, 2, 20, 20), dtype=float32) • mask=tf.Tensor(shape=(4, 5, 1, 5, 20), dtype=bool) mask_zero = False","The expectation here is that the attention is applied on the 2nd dimension (4, 5, 20, 64). I am trying to apply self attention using the following code (issue reproducible with this code): However, the above layer defined throws the following error. Could someone please explain why is this happening &amp; how to fix this? PS: If I set in defining the embedding layer, the code runs fine as expected without any issues."
Model Bug,59278771,"# Multiclass Classification with the Iris Flowers Dataset import numpy import pandas from keras.models import Sequential from keras.layers import Dense from keras.wrappers.scikit_learn import KerasClassifier from keras.utils import np_utils from sklearn.model_selection import cross_val_score from sklearn.model_selection import KFold from sklearn.preprocessing import LabelEncoder from sklearn.pipeline import Pipeline # fix random seed for reproducibility seed = 7 numpy.random.seed(seed) # load dataset dataframe = pandas.read_csv(""/content/drive/My Drive/iris.data"", header=None) dataset = dataframe.values X = dataset[:,0:4].astype(float) Y = dataset[:,4] # encode class values as integers encoder = LabelEncoder() encoder.fit(Y) encoded_Y = encoder.transform(Y) # convert integers to dummy variables (i.e. one hot encoded) dummy_y = np_utils.to_categorical(encoded_Y) # define baseline model def baseline_model(): # create model model = Sequential() model.add(Dense(4, input_dim=4, activation=""relu"", kernel_initializer=""normal"")) model.add(Dense(3, activation=""sigmoid"", kernel_initializer=""normal"")) # Compile model model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ]) return model estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=200, batch_size=5, verbose=0) kfold = KFold(n_splits=10, shuffle=True, random_state=seed) results = cross_val_score(estimator, X, dummy_y, cv=kfold) print(""Accuracy: %.2f%% (%.2f%%)"" % (results.mean()*100, results.std()*100)) 95.33% (4.27%) ~Accuracy: 34.00% (13.15%)",I followed a tutorial on neural network model evaluation using cross-validation with code: The accuracy was supposed to be around but I got on a few attempts. The model code seems exactly the same. I downloaded the data from here as instructed. What could go wrong? Thanks
Model Bug,76186890,"from transformers import T5Tokenizer, T5ForConditionalGeneration import torch tokenizer = T5Tokenizer.from_pretrained(&quot;t5-small&quot;) model = T5ForConditionalGeneration.from_pretrained(&quot;t5-small&quot;) context_1 = 'here is some context_1 and some more stuff' context_2 = 'here is some context and some more stuff and more stuff aspodkaspd' answer_1 = 'this is not the answer' input_ids_wrong = tokenizer(context_1 + answer_1, return_tensors=&quot;pt&quot;).input_ids input_ids_correct = tokenizer(context_2 + answer_1, return_tensors=&quot;pt&quot;).input_ids context_1_tokens_length = len(tokenizer(context_1, return_tensors=&quot;pt&quot;).input_ids[0]) context_2_tokens_length = len(tokenizer(context_2, return_tensors=&quot;pt&quot;).input_ids[0]) target_ids_wrong = input_ids_wrong.clone() target_ids_correct = input_ids_correct.clone() target_ids_wrong[:, :context_1_tokens_length] = -100 target_ids_correct[:, :context_2_tokens_length] = -100 print('target_ids_wrong', target_ids_wrong) print('target_ids_correct', target_ids_correct) with torch.no_grad(): outputs_wrong = model(input_ids_wrong, labels=target_ids_wrong) outputs_correct = model(input_ids_correct, labels=target_ids_correct) neg_log_likelihood_wrong = outputs_wrong.loss neg_log_likelihood_correct = outputs_correct.loss ppl_wrong = torch.exp(neg_log_likelihood_wrong) ppl_correct = torch.exp(neg_log_likelihood_correct) print('ppl_wrong', ppl_wrong) print('ppl_correct', ppl_correct) target_ids_wrong tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 19, 59, 8, 1525, 1]]) target_ids_correct tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 19, 59, 8, 1525, 1]]) ppl_wrong tensor(9.0377) ppl_correct tensor(21.1208) gpt2 sshleifer/tiny-gpt2 -100 0 -100 -100","I'm following Huggingface doc on calculating the perplexity of fixed-length models. I'm trying to verify that the formula works for various strings and I'm getting odd behavior. In particular, they mention We don’t want the log-likelihood for the tokens we’re just treating as context to be included in our loss, so we can set these targets to -100 so that they are ignored So given 2 different contexts but the same remaining tokens, the formula should return the same perplexity. However, it does not: Output: I tried this with other models as well (e.g., and ) and got the same odd behavior. From the T5 doc they wrote we must make sure that padding token id’s of the labels are not taken into account by the loss function. In PyTorch and Tensorflow, this can be done by replacing them with -100, which is the ignore_index of the CrossEntropyLoss. So I don't understand why it takes the pad token into account. They also wrote in the same link which for T5 is equal to 0 (i.e. the id of the pad token) So I tried replacing the with and actually a got different perplexity score (still different than each other, but different than the ). Which makes me think they don't actually ignore the token for some reason. Am I missing something?"
Model Bug,55731589,"``ValueError: Negative dimension size caused by subtracting 3 from 2 for 'conv2d_24/convolution' (op: 'Conv2D') with input shapes: [?,2,2,128], [3,3,128,128]. from keras import layers from keras import models model = models.Sequential() model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(64, (3, 3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(128, (3, 3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(128, (3, 3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Flatten()) model.add(layers.Dense(512, activation='relu')) model.add(layers.Dense(1, activation='sigmoid'))","I got this error when using Keras: Is it because input_size not larger than the filter? If input_shape=(64,64,3))), there will be no error. My code are here:"
Tensor and Input Bug,73276139,"import torch from torch import nn kernel_size = 7 stride = 1 # approach 1 data = torch.rand(4, 64, 174, 120) data1 = data.unfold(3, kernel_size * 2 + 1, stride) print(data1.shape) # approach 2 data = torch.rand(4, 64, 174, 120) unfold = nn.Unfold(3, kernel_size * 2 + 1, stride) data2 = unfold(data) print(data2.shape) torch.Size([4, 64, 174, 106, 15]) torch.Size([4, 576, 13432]) import torch from torch import nn kernel_size = 7 stride = 1 # approach 1 data = torch.rand(4, 64, 174, 120) data1 = data.unfold(3, kernel_size * 2 + 1, stride) print(data1.shape) # approach 2 data = torch.rand(4, 64, 174, 120) b, c, h, w = data.shape unfold = nn.Unfold(kernel_size=(1, 2*kernel_size + 1), dilation=1, stride=1, padding=0) data2 = unfold(data.reshape(-1, 1, 1, w)).permute(0, 2, 1).reshape(b, c, h, -1, 2*kernel_size + 1) print(data2.shape) print(torch.equal(data1, data2)) torch.Size([4, 64, 174, 106, 15]) torch.Size([4, 64, 174, 106, 15]) False","Why is this giving me two completely different answers? And how can I get the same result as in approach 1, using approach 2? Output: EDIT ------------------------------------------ I tried your approach @Shai. The shapes are the same, but the content is not. Any idea why? Output:"
Tensor and Input Bug,55955130,"x (10000, 28, 28) y (10000,) x = x.reshape(-1, 28, 28, 1) model = Sequential([ Conv2D(8, kernel_size=(3, 3), padding=""same"", activation=tf.nn.relu, input_shape=(28, 28, 1)), Dense(64, activation=tf.nn.relu), Dense(64, activation=tf.nn.relu), Dense(10, activation=tf.nn.softmax) ]) model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) model.fit(x, y, epochs=5) #error ValueError: Error when checking target: expected dense_3 to have 4 dimensions, but got array with shape (10000, 1) model.summary() Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 28, 28, 8) 80 _________________________________________________________________ dense_1 (Dense) (None, 28, 28, 64) 576 _________________________________________________________________ dense_2 (Dense) (None, 28, 28, 64) 4160 _________________________________________________________________ dense_3 (Dense) (None, 28, 28, 10) 650 ================================================================= Total params: 5,466 Trainable params: 5,466 Non-trainable params: 0 _________________________________________________________________","I have dataset of 28x28 pictures. Datapoints array has shape , labels array has shape . The following code: gives: output:"
Tensor and Input Bug,70233512,"a = tf.constant([[1, 2, 3], [1, 2, 3]]) b = tf.constant([1, 2, 3, 4, 5]) &lt;tf.Tensor: shape=(4, 2), dtype=int64, numpy= array([[1, 2, 3, 0, 0], [1, 2, 3, 0, 0], [1, 2, 3, 4, 5]], dtype=int64)&gt; tf.concat([a, b], axis=0) InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [2,3] vs. shape[1] = [1,5] [Op:ConcatV2] name: concat",I have 2 tensors like: My desired output would be: But when I try I get this error:
Tensor and Input Bug,67764431,"x = tf.range(0,64*5) x = tf.reshape(x, [1,5, 64]) y = tf.range(0,5) y = tf.reshape(y, [1, 5]) prodct = x*y InvalidArgumentError: Incompatible shapes: [1,5,64] vs. [1,5] [Op:Mul] x = tf.range(0,64*5) x = tf.reshape(x, [1,64, 5]) y = tf.range(0,5) y = tf.reshape(y, [1, 5]) prodct = x*y","I am trying to do element-wise multiplication of two tensors of dimensions (1,5,64) and (1,5). As far as I know, in spite of their dimension mismatch, broadcasting should allow this to work. So, I use this code: This causes this error: However If i reshape first tensor to dimension (1,64,5), then it works. Code: I do not understand why the first code does not work."
Tensor and Input Bug,70316929,"Traceback (most recent call last): File &quot;/Users/DevDog/Documents/vsc/pokemon/dementad.py&quot;, line 44, in &lt;module&gt; im =transforms.ToPILImage()(img[0]).convert('RGBA') File &quot;/Users/DevDog/miniforge3/envs/python386/lib/python3.8/site-packages/torchvision/transforms/transforms.py&quot;, line 179, in __call__ return F.to_pil_image(pic, self.mode) File &quot;/Users/DevDog/miniforge3/envs/python386/lib/python3.8/site-packages/torchvision/transforms/functional.py&quot;, line 290, in to_pil_image raise TypeError('Input type {} is not supported'.format(npimg.dtype)) TypeError: Input type int64 is not supported import fastai from fastai.data import transforms from fastai.data.block import DataBlock, TransformBlock from fastai.data.transforms import get_image_files from fastai.optimizer import RMSProp from fastai.vision.data import ImageBlock, ImageDataLoaders from fastcore.imports import noop from numpy import negative import torch import cv2 import PIL from torchvision import transforms from PIL import Image from torch import nn from fastai.vision import * from fastai.vision.augment import * from fastai.imports import * from fastai.vision.gan import * from fastai.data.block import * from fastai.data.transforms import * from fastai.callback.all import * path = Path('pokeman') bs=100 size=64 dblock = DataBlock(blocks = (TransformBlock, ImageBlock), get_x = generate_noise, get_items = get_image_files, splitter = IndexSplitter([]), item_tfms=Resize(size, method=ResizeMethod.Crop), batch_tfms = Normalize.from_stats(torch.tensor([0.5,0.5,0.5]), torch.tensor([0.5,0.5,0.5]))) dls = dblock.dataloaders(path,path=path,bs=bs) generator = basic_generator(64,3,n_extra_layers=1) critic = basic_critic(64, 3, n_extra_layers=1,act_cls=partial(nn.LeakyReLU)) student = GANLearner.wgan(dls,generator,critic,opt_func = RMSProp) student.recorder.train_metrics=True student.recorder.valid_metrics=False student.fit(1,2e-4,wd=0.) #cv2.waitKey(0) student.show_results(max_n=9,ds_idx=0) student.gan_trainer.switch(gen_mode=True) img = student.predict(generate_noise('pocheman',size=100)) print(img[0].size()) im =transforms.ToPILImage()(img[0]).convert('RGB')",I'm trying to develop a GAN using FastAi. When converting the Tensor to an Image I get this error. Here's the full code The point of the Code is to generate pokemon images. But whenever I predict and convert it to a PIL Image the code fails with the aforementioned error.
Tensor and Input Bug,43464835,"(300, 5, 720) [[[ 6. 11. 389. ..., 0. 0. 0.] [ 2. 0. 0. ..., 62. 0. 0.] [ 0. 0. 18. ..., 0. 0. 0.] [ 38. 201. 47. ..., 0. 108. 0.] [ 0. 0. 1. ..., 0. 0. 0.]] [[ 136. 95. 0. ..., 0. 0. 0.] [ 85. 88. 85. ..., 0. 31. 0.] [ 0. 0. 0. ..., 0. 0. 0.] [ 0. 0. 0. ..., 0. 0. 0.] [ 13. 19. 0. ..., 0. 0. 0.]]] (5,720) cnn = Sequential() cnn.add(Conv2D(64, (5, 50), padding=""same"", activation=""relu"",data_format=""channels_last"", input_shape=in_shape)) cnn.add(MaxPooling2D(pool_size=(2,2),data_format=""channels_last"")) cnn.add(Flatten()) cnn.add(Dropout(0.5)) cnn.add(Dense(number_of_classes, activation=""softmax"")) cnn.compile(loss=""categorical_crossentropy"", optimizer=""adam"", metrics= ['accuracy']) cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True) rows,cols=x_train.shape[1:] in_shape=(rows,cols,1)","I have a train dataset of the following shape: I am trying to pass each sample as input to the cnn model, each input is of size ,I am using the following model in keras: I am using input shape as: but I am getting the following error: ValueError: Error when checking model input: expected conv2d_1_input to have 4 dimensions, but got array with shape (300, 5, 720) How can I fix this error?"
Tensor and Input Bug,41651628,"import numpy as np np.random.seed(1373) import tensorflow as tf tf.python.control_flow_ops = tf import os from keras.datasets import mnist from keras.models import Sequential from keras.layers.core import Dense, Dropout, Activation, Flatten from keras.layers.convolutional import Convolution2D, MaxPooling2D from keras.utils import np_utils batch_size = 128 nb_classes = 10 nb_epoch = 12 img_rows, img_cols = 28, 28 nb_filters = 32 nb_pool = 2 nb_conv = 3 (X_train, y_train), (X_test, y_test) = mnist.load_data() print(X_train.shape[0]) X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols) X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols) X_train = X_train.astype('float32') X_test = X_test.astype('float32') X_train /= 255 X_test /= 255 print('X_train shape:', X_train.shape) print(X_train.shape[0], 'train samples') print(X_test.shape[0], 'test samples') Y_train = np_utils.to_categorical(y_train, nb_classes) Y_test = np_utils.to_categorical(y_test, nb_classes) model = Sequential() model.add(Convolution2D(nb_filters, nb_conv, nb_conv, border_mode='valid', input_shape=(1, img_rows, img_cols))) model.add(Activation('relu')) model.add(Convolution2D(nb_filters, nb_conv, nb_conv)) model.add(Activation('relu')) model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(128)) model.add(Activation('relu')) model.add(Dropout(0.5)) model.add(Dense(nb_classes)) model.add(Activation('softmax')) model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=[""accuracy""]) model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_test, Y_test)) score = model.evaluate(X_test, Y_test, verbose=0) print('Test score:', score[0]) print('Test accuracy:', score[1]) Using TensorFlow backend. 60000 ('X_train shape:', (60000, 1, 28, 28)) (60000, 'train samples') (10000, 'test samples') Traceback (most recent call last): File ""mnist.py"", line 154, in &lt;module&gt; input_shape=(1, img_rows, img_cols))) File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 276, in add layer.create_input_layer(batch_input_shape, input_dtype) File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 370, in create_input_layer self(x) File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 514, in __call__ self.add_inbound_node(inbound_layers, node_indices, tensor_indices) File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 572, in add_inbound_node Node.create_node(self, inbound_layers, node_indices, tensor_indices) File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 149, in create_node output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0])) File ""/usr/local/lib/python2.7/dist-packages/keras/layers/convolutional.py"", line 466, in call filter_shape=self.W_shape) File ""/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py"", line 1579, in conv2d x = tf.nn.conv2d(x, kernel, strides, padding=padding) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 396, in conv2d data_format=data_format, name=name) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op op_def=op_def) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op set_shapes_for_outputs(ret) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs shapes = shape_func(op) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring return call_cpp_shape_fn(op, require_shape_fn=True) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn debug_python_shape_fn, require_shape_fn) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl raise ValueError(err.message) ValueError: Negative dimension size caused by subtracting 3 from 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,1,28,28], [3,3,28,32]. Tensorflow Tensorflow 0.12.0 input_shape ./keras/keras.json { ""image_dim_ordering"": ""tf"", ""epsilon"": 1e-07, ""floatx"": ""float32"", ""backend"": ""tensorflow"" }","I'm using Keras with Tensorflow as backend , here is my code: and Trackback error: First I saw some answers that problem is with version so I upgrade to , but still exist , is that problem with network or I missing something, what should looks like? Update Here is :"
Tensor and Input Bug,71652014,"tensor([[ 1., -5.], [ 2., -4.], [ 3., 2.], [ 4., 1.], [ 5., 2.]]) tensor([[-1., 1.], [ 1., -1.]], requires_grad=True) apply_i = lambda x: torch.matmul(x, i) final = pytorch.tensor([apply_i(a) for a in x])","I currently have a tensor that looks like this (numbers randomly selected), which I will call x: I also have another 2D tensor (call it i) I hope to pytorch.matmul i to each row in x. Is there a way for me to achieve this? Below is my attempt: It throws an error saying &quot;only one element tensors can be converted to Python scalars&quot;. Does not work even when I remove the square bracket. Any help would be appreciated!"
Tensor and Input Bug,73266661,"(torch.Size([1, 3, 224, 224])) (torch.Size([1, 96])) class MixedNetwork(nn.Module): def __init__(self): super(MixedNetwork, self).__init__() image_modules = list(models.resnet50().children())[:-1] self.image_features = nn.Sequential(*image_modules) self.landmark_features = nn.Sequential( nn.Linear(in_features=96, out_features=192,bias=False), nn.ReLU(inplace=True), nn.Dropout(p=0.25), nn.Linear(in_features=192,out_features=1000,bias=False), nn.ReLU(inplace=True), nn.Dropout(p=0.25)) self.combined_features = nn.Sequential( nn.Linear(1000, 512), nn.ReLU(), nn.Linear(512, 32), nn.ReLU(), nn.Linear(32,1)) def forward(self, image, landmarks): a = self.image_features(image) print(a.shape) b = self.landmark_features(landmarks) x = torch.cat((a.view(a.size(0), -1), b.view(b.size(0), -1)), dim=1) x = self.combined_features(x) x = F.sigmoid(x) return x","Good afternoon! I’m building a multiple-input model with 2 types of inputs: Images and landmark features . Here’s the model itself: I’m getting confused when it comes to defining input-output features for Linear layers and combined layers. The last FC layer of resnet50 Linear(in_features=2048, out_features=1000). Does it mean that the last output of self.landmark_features layers also has to be 1000 and the first linear layer of self.combined_features should also be 1000? Is it correct to assume that if the landmark input size is [1, 96] then the in_features for the first layer of self.landmark_features has to be 96? With the current dimensions I’m getting the error message: RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x3048 and 1000x512) (why 3048 and not 2048?)"
Tensor and Input Bug,63204176,"TypeError: 'Tensor' object is not callable Traceback (most recent call last): File &quot;/snap/pycharm-community/207/plugins/python-ce/helpers/pydev/pydevd.py&quot;, line 1448, in _exec pydev_imports.execfile(file, globals, locals) # execute the script File &quot;/snap/pycharm-community/207/plugins/python-ce/helpers/pydev/_pydev_imps/_pydev_execfile.py&quot;, line 18, in execfile exec(compile(contents+&quot;\n&quot;, file, 'exec'), glob, loc) File &quot;/home/pytorch_tutorial/Pytorch_feed_fwd_310720.py&quot;, line 78, in &lt;module&gt; loss = loss(preds,ys) TypeError: 'Tensor' object is not callable loss = nn.CrossEntropyLoss() for epoch in range(5): running_loss = 0.0 for i, data in enumerate(trainloader, 0): xs, ys = data opt.zero_grad() preds = net(xs) loss = loss(preds,ys) loss.backward() opt.step() # print statistics running_loss += loss.item() if i % 1000 == 999: # print every 1000 mini-batches print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print('epoch {}, loss {}'.format(epoch, loss.item())) a=1","I use Python 3.x, and pytorch 1.5.0 with a GPU. I am trying to write a simple multinomial logistic regression using mnist data. My issue is the loss() function throws a while looping through the training batches. The thing that baffles me is that the error does not show up in the first iteration of the loop, but for the second batch, I get the full error below: The loss() function here is simply . The full code is below. Any pointers would be very welcome."
Training Bug,48934338,"#datapoints X = np.arange(0.0, 5.0, 0.1, dtype='float32').reshape(-1,1) y = 5 * np.power(X,2) + np.power(np.random.randn(50).reshape(-1,1),3) #model model = Sequential() model.add(Dense(50, activation='relu', input_dim=1)) model.add(Dense(30, activation='relu', init='uniform')) model.add(Dense(output_dim=1, activation='linear')) #training sgd = SGD(lr=0.1); model.compile(loss='mse', optimizer=sgd, metrics=['accuracy']) model.fit(X, y, nb_epoch=1000) #predictions predictions = model.predict(X) #plot plt.scatter(X, y,edgecolors='g') plt.plot(X, predictions,'r') plt.legend([ 'Predictated Y' ,'Actual Y']) plt.show()",I just started learning keras. I am trying to train a non-linear regression model in keras but model doesn't seem to learn much. what am I doing wrong?
Training Bug,51930566,"X = dataset[:,0:4].astype(float) model = Sequential() model.add(Dense(4, input_dim=4, init='normal', activation='relu')) model.add(Dense(3, init='normal', activation='sigmoid')) model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) model = Sequential() model.add(Dense(8, input_dim=4, init='normal', activation='relu')) model.add(Dense(3, init='normal', activation='sigmoid')) model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","I am trying to create an neural network based on the iris dataset. I have an input of four dimensions. . Then, I create a neural network with four nodes. As I understand, I pass each dimension to the separate node. Four dimensions - four nodes. When I create a neural network with 8 input nodes, how does it work? Performance still is the same as with 4 nodes."
Training Bug,50306988,"model = Sequential() model.add(Dense(units=2, activation='sigmoid', input_shape= (nr_feats,))) model.add(Dense(units=nr_classes, activation='softmax')) model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) nr_feats nr_classes from sklearn.preprocessing import LabelEncoder x_train = df_train.iloc[:,0:-1].values y_train = df_train.iloc[:, -1] nr_feats = x_train.shape[1] nr_classes = y_train.nunique() label_enc = LabelEncoder() label_enc.fit(y_train) y_train = keras.utils.to_categorical(label_enc.transform(y_train), nr_classes) model.fit(x_train, y_train, epochs=500, batch_size=32, verbose=True) accuracy_score(model.predict_classes(x_train), df_train.iloc[:, -1].values) binary_crossentropy","I have created the following toy dataset: I am trying to predict the class with a neural net in keras: With and set to 2. The neural net can only predict with 50 percent accuracy returning either all 1's or all 2's. Using Logistic Regression results in 100 percent accuracy. I can not find what is going wrong here. I have uploaded a notebook to github if you quickly want to try something. EDIT 1 I drastically increased the number of epochs and accuracy finally starts to improve from 0.5 at epoch 72 and converges to 1.0 at epoch 98. This still seems extremely slow for such a simple dataset. I am aware it is better to use a single output neuron with sigmoid activation but it's more that I want to understand why it does not work with two output neurons and softmax activation. I pre-process my dataframe as follows: Training and evaluation: EDIT 2 After changing the output layer to a single neuron with sigmoid activation and using loss as modesitt suggested, accuracy still remains at 0.5 for 200 epochs and converges to 1.0 100 epochs later."
Training Bug,31880720,"keras.datasets import mnist (x_tr, y_tr), (x_te, y_te) = mnist.load_data() print x_tr.shape (60000, 28, 28) X_train = numpy.array([[1] * 128] * (10 ** 4) + [[0] * 128] * (10 ** 4)) X_test = numpy.array([[1] * 128] * (10 ** 2) + [[0] * 128] * (10 ** 2)) Y_train = numpy.array([True] * (10 ** 4) + [False] * (10 ** 4)) Y_test = numpy.array([True] * (10 ** 2) + [False] * (10 ** 2)) X_train = X_train.astype(""float32"") X_test = X_test.astype(""float32"") Y_train = Y_train.astype(""bool"") Y_test = Y_test.astype(""bool"") model = Sequential() model.add(Dense(128, 50)) model.add(Activation('relu')) model.add(Dropout(0.2)) model.add(Dense(50, 50)) model.add(Activation('relu')) model.add(Dropout(0.2)) model.add(Dense(50, 1)) model.add(Activation('softmax')) rms = RMSprop() model.compile(loss='binary_crossentropy', optimizer=rms) model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=2, validation_data=(X_test, Y_test)) score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0) print('Test score:', score[0]) print('Test accuracy:', score[1]) Test score: 13.9705320154 Test accuracy: 1.0",Motivation To run a set of labeled vectors through Keras neural network. Example Looking at Keras dataset example mnist: It seem to be a 3 dimensional numpy array: 1st dimension is for the samples 2nd and 3rd for each sample features Attempt Building the labeled vectors: The training code Result Why do I get such a bad result for such a simple dataset? Is my dataset malformed? Thanks!
Training Bug,71457035,"import torch from torch import nn, optim import torch.nn.functional as F X_train_t = torch.tensor(X_train).float() X_test_t = torch.tensor(X_test).float() y_train_t = torch.tensor(y_train).long().reshape(y_train_t.shape[0], 1) y_test_t = torch.tensor(y_test).long().reshape(y_test_t.shape[0], 1) class Classifier(nn.Module): def __init__(self): super().__init__() self.fc1 = nn.Linear(22, 10) self.fc2 = nn.Linear(10, 1) def forward(self, x): # make sure input tensor is flattened x = x.view(x.shape[0], -1) x = F.relu(self.fc1(x)) x = F.log_softmax(self.fc2(x), dim=1) return x model = Classifier() criterion = nn.BCELoss() optimizer = optim.SGD(model.parameters(), lr=0.003) epochs = 2000 steps = 0 train_losses, test_losses = [], [] for e in range(epochs): # training loss optimizer.zero_grad() log_ps = model(X_train_t) loss = criterion(log_ps, y_train_t.type(torch.float32)) loss.backward() optimizer.step() train_loss = loss.item() # test loss # Turn off gradients for validation, saves memory and computations with torch.no_grad(): log_ps = model(X_test_t) test_loss = criterion(log_ps, y_test_t.to(torch.float32)) ps = torch.exp(log_ps) train_losses.append(train_loss/len(X_train_t)) test_losses.append(test_loss/len(X_test_t)) if (e % 100 == 0): print(&quot;Epoch: {}/{}.. &quot;.format(e, epochs), &quot;Training Loss: {:.3f}.. &quot;.format(train_loss/len(X_train_t)), &quot;Test Loss: {:.3f}.. &quot;.format(test_loss/len(X_test_t))) Epoch: 0/2000.. Training Loss: 0.014.. Test Loss: 0.082.. Epoch: 100/2000.. Training Loss: 0.014.. Test Loss: 0.082.. ...","I have a bespoke NN model which works and wanted to move it to the PyTorch framework. However, the network is not training likely due to some misconfiguration. Please advise if you see something that is odd/wrong or could be a contributing reason. Training is not happening:"
Training Bug,63176966,"AdditiveGaussianNoise from skimage.io import imread from skimage.transform import resize import imgaug.augmenters as iaa file_name = &quot;path/to/image.jpg&quot; resized_img = resize(imread(file_name), (224, 224)) aug = iaa.AdditiveGaussianNoise(scale=(0, 0.2*255)) augmented_image = aug(resized_img) --------------------------------------------------------------------------- AssertionError Traceback (most recent call last) &lt;ipython-input-20-e4a0b17d4ac4&gt; in &lt;module&gt;() ----&gt; 1 augmented_image =aug(resized_img) 1 frames /usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py in augment(self, return_batch, hooks, **kwargs) 1782 (&quot;Expected boolean as argument for 'return_batch', got type %s. &quot; 1783 + &quot;Call augment() only with named arguments, e.g. &quot; -&gt; 1784 + &quot;augment(images=&lt;array&gt;).&quot;) % (str(type(return_batch)),) 1785 ) 1786 AssertionError: Expected boolean as argument for 'return_batch', got type &lt;class 'numpy.ndarray'&gt;. Call augment() only with named arguments, e.g. augment(images=&lt;array&gt;).",I would like to add (link: https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#additivegaussiannoise) to a single image which I resized before. This is my code: And I get this error message: How do I have to amend my code? Thank you very much!
Training Bug,65992364,".pt zip import torch import torchvision from torch.utils.mobile_optimizer import optimize_for_mobile model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) model.eval() script_model = torch.jit.script(model) from torch.utils.mobile_optimizer import optimize_for_mobile script_model_vulkan = optimize_for_mobile(script_model, backend='Vulkan') torch.jit.save(script_model_vulkan, &quot;frcnn.pth&quot;)","I want to reduce the object detection model size. For the same, I tried optimising Faster R-CNN model for object detection using pytorch-mobile optimiser, but the file generated is of the same size as that of the original model size. I used the code mention below"
Training Bug,66818548,"# here is a one-hot encoded vector for the multi-label classification # the image thus has 2 correct labels out of a possible 3 classes y = [0, 1, 1] # these are some made up logits that might come from the network. vec = torch.tensor([0.2, 0.9, 0.7]) def concurrent_softmax(vec, y): for i in range(len(vec)): zi = torch.exp(vec[i]) sum_over_j = 0 for j in range(len(y)): sum_over_j += (1-y[j])*torch.exp(vec[j]) out = zi / (sum_over_j + zi) yield out for result in concurrent_softmax(vec, y): print(result)","I am trying to implement the so called 'concurrent' softmax function given in the paper &quot;Large-Scale Object Detection in the Wild from Imbalanced Multi-Labels&quot;. Below is the definition of the concurrent softmax: NOTE: I have left the (1-rij) term out for the time being because I don't think it applies to my problem given that my training dataset has a different type of labeling compared to the paper. To keep it simple for myself I am starting off by implementing it in a very inefficient, but easy to follow, way using for loops. However, the output I get seems wrong to me. Below is the code I am using: From this implementation I have realized that, no matter what value I give to the first logit in 'vec' I will always get an output of 0.5 (because it essentially always calculates zi / (zi+zi)). This seems like a major problem, because I would expect the value of the logits to have some influence on the resulting concurrent-softmax value. Is there a problem in my implementation then, or is this behaviour of the function correct and there is something theoretically that I am not understanding?"
Training Bug,48251943,"from keras.models import Sequential from keras.layers import Dense import numpy #fix random seed for reproducibility numpy.random.seed(7) #load and read dataset dataset = numpy.loadtxt(""Phenols-toxicity.csv"", delimiter="";"") # split into input (X) and output (Y) variables X = dataset[:,2:4] Y = dataset[:,1] print (""Variables: \n"", X) print (""Target_outputs: \n"", Y) # create model model = Sequential() model.add(Dense(4, input_dim=2, activation='relu')) #model.add(Dense(4, activation='relu')) model.add(Dense(1, activation='relu')) model.summary() # Compile model model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['MSE']) # Fit the model model.fit(X, Y, epochs=500, batch_size=10) #make predictions (test) F = model.predict(X) print (""Predicted values: \n"", F) [ 0.085 2.468 0.07 0.68 -0.184 0.545 -0.063 0.871 0.113 -0.208 0.688 1.638 2.03 0.078 0.573 1.036 0.015 -0.03 -0.381 0.701 0.205 0.266 1.796 2.033 0.168 2.097 1.081 -0.384 0.377 -0.326 -0.143 1.292 0.701 0.334 1.157 1.638 -0.046 0.343 1.167 1.301 0.277 1.131 0.471 0.617 0.707 0.185 0.604 0.017 0.381 0.804 0.618 2.712 -0.092 -0.826 0.122 0.932 0.281 0.854 1.276 2.574 1.125 0.73 0.796 1.145 1.569 2.664 0.034 1.398 0.393 0.612 -0.78 0.228 -1.043 -0.141 0.013 1.119 0.643 -0.242 0.757 -0.299 0.599 0.36 1.778 0.053 1.268 1.276 0.516 1.167 1.638 0.478 1.229 0.735 2.049 -0.064 1.201 1.41 1.295 0.798 1.854 0.16 -0.954 0.424 -0.51 1.638 -0.598 2.373 2.222 -0.358 -0.295 0.33 0.183 0.122 1.745 0.081 2.097 0.914 0.979 0.084 0.473 -0.302 0.879 0.366 0.172 0.45 1.307 0.886 -0.524 1.174 -0.512 0.939 0.775 -1.053 -0.814 0.475 -1.021 1.42 -0.82 0.654 0.571 -0.076 0.74 1.729 0.75 1.712 0.95 0.33 1.125 1.077 1.721 0.506 0.539 0.266 1.745 1.229 0.632 1.585 -0.155 0.463 1.638 0.67 -0.155 2.053 0.379 0.181 0.253 1.356] [[ 0. ] [ 2.03844833] [ 0.27423561] [ 0.59996957] [ 0. ] [ 0.44271404] [ 0. ] [ 0.47064281] [ 0.29890585] [ 0. ] [ 0.95044041] [ 1.84322166] [ 1.93953323] [ 0.18019629] [ 0.68691438] [ 0.96168059] [ 0.13934678] [ 0. ] [ 0. ] [ 0.87886989] [ 0.30047321] [ 0. ] [ 1.90942693] [ 1.83728123] [ 0. ] [ 1.84627008] [ 1.25797462] [ 0. ] [ 0.01434445] [ 0. ] [ 0. ] [ 1.1421392 ] [ 0.83652729] [ 0.37334418] [ 1.72099805] [ 1.73340106] [ 0.30456764] [ 0. ] [ 1.37316585] [ 1.34221601] [ 0.6739701 ] [ 0.79646528] [ 0.03717542] [ 0.35218674] [ 0.09512168] [ 0. ] [ 0.20107687] [ 0. ] [ 0.01262379] [ 1.00669646] [ 0.96650052] [ 2.10064697] [ 0. ] [ 0. ] [ 0.25874525] [ 0.61007023] [ 0.68899512] [ 0.81215698] [ 0.88977867] [ 2.43740511] [ 1.00497019] [ 0.94933379] [ 0.83326894] [ 0.63394952] [ 1.27170706] [ 2.56578207] [ 0. ] [ 1.29493976] [ 0.599581 ] [ 0.63211834] [ 0. ] [ 0.31536853] [ 0. ] [ 0. ] [ 0.02201092] [ 0.84008563] [ 0.73076451] [ 0. ] [ 0.4879511 ] [ 0. ] [ 0.77698141] [ 0.66419512] [ 1.56657863] [ 0.25022489] [ 1.36990726] [ 1.50250816] [ 0. ] [ 0.61219454] [ 0.87011993] [ 0.72275633] [ 1.36519527] [ 0.72287238] [ 2.3798852 ] [ 0. ] [ 1.23592615] [ 1.43725252] [ 0.95585048] [ 0.63723856] [ 1.8765614 ] [ 0.31583393] [ 0. ] [ 0.14386666] [ 0. ] [ 1.68151355] [ 0. ] [ 1.63394952] [ 1.97563386] [ 0. ] [ 0. ] [ 0.38875413] [ 0.18854523] [ 0.23547113] [ 1.13463831] [ 0.30076784] [ 1.61114097] [ 0.93304199] [ 1.04891086] [ 0.26546735] [ 0.62234318] [ 0. ] [ 0. ] [ 0.21855426] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0.39396375] [ 0.45845711] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0.4718284 ] [ 0. ] [ 0. ] [ 0.91218936] [ 0. ] [ 0.82205164] [ 0.78155482] [ 0.98432505] [ 2.15232277] [ 0.97631133] [ 0.59527659] [ 0.83814716] [ 0.80036032] [ 1.17462301] [ 0.51232517] [ 0.82968521] [ 0.9463613 ] [ 1.69353771] [ 1.21046495] [ 1.36349583] [ 0.94378138] [ 0. ] [ 0.98034143] [ 1.66670561] [ 0.52768588] [ 0.93855476] [ 1.26870298] [ 0. ] [ 0. ] [ 0. ] [ 1.69362605]] [[ 0. ] [ 2.03844833] [ 0.27423561] [ 0.59996957] [ 0. ] [ 0.44271404] [ 0. ] [ 0.47064281] [ 0.29890585] [ 0. ] [ 0.95044041] [ 1.84322166] [ 1.93953323] [ 0.18019629] [ 0.68691438] [ 0.96168059] [ 0.13934678] [ 0. ] [ 0. ] [ 0.87886989] [ 0.30047321] [ 0. ] [ 1.90942693] [ 1.83728123] [ 0. ] [ 1.84627008] [ 1.25797462] [ 0. ] [ 0.01434445] [ 0. ] [ 0. ] [ 1.1421392 ] [ 0.83652729] [ 0.37334418] [ 1.72099805] [ 1.73340106] [ 0.30456764] [ 0. ] [ 1.37316585] [ 1.34221601] [ 0.6739701 ] [ 0.79646528] [ 0.03717542] [ 0.35218674] [ 0.09512168] [ 0. ] [ 0.20107687] [ 0. ] [ 0.01262379] [ 1.00669646] [ 0.96650052] [ 2.10064697] [ 0. ] [ 0. ] [ 0.25874525] [ 0.61007023] [ 0.68899512] [ 0.81215698] [ 0.88977867] [ 2.43740511] [ 1.00497019] [ 0.94933379] [ 0.83326894] [ 0.63394952] [ 1.27170706] [ 2.56578207] [ 0. ] [ 1.29493976] [ 0.599581 ] [ 0.63211834] [ 0. ] [ 0.31536853] [ 0. ] [ 0. ] [ 0.02201092] [ 0.84008563] [ 0.73076451] [ 0. ] [ 0.4879511 ] [ 0. ] [ 0.77698141] [ 0.66419512] [ 1.56657863] [ 0.25022489] [ 1.36990726] [ 1.50250816] [ 0. ] [ 0.61219454] [ 0.87011993] [ 0.72275633] [ 1.36519527] [ 0.72287238] [ 2.3798852 ] [ 0. ] [ 1.23592615] [ 1.43725252] [ 0.95585048] [ 0.63723856] [ 1.8765614 ] [ 0.31583393] [ 0. ] [ 0.14386666] [ 0. ] [ 1.68151355] [ 0. ] [ 1.63394952] [ 1.97563386] [ 0. ] [ 0. ] [ 0.38875413] [ 0.18854523] [ 0.23547113] [ 1.13463831] [ 0.30076784] [ 1.61114097] [ 0.93304199] [ 1.04891086] [ 0.26546735] [ 0.62234318] [ 0. ] [ 0. ] [ 0.21855426] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0.39396375] [ 0.45845711] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0. ] [ 0.4718284 ] [ 0. ] [ 0. ] [ 0.91218936] [ 0. ] [ 0.82205164] [ 0.78155482] [ 0.98432505] [ 2.15232277] [ 0.97631133] [ 0.59527659] [ 0.83814716] [ 0.80036032] [ 1.17462301] [ 0.51232517] [ 0.82968521] [ 0.9463613 ] [ 1.69353771] [ 1.21046495] [ 1.36349583] [ 0.94378138] [ 0. ] [ 0.98034143] [ 1.66670561] [ 0.52768588] [ 0.93855476] [ 1.26870298] [ 0. ] [ 0. ] [ 0. ] [ 1.69362605]]","I would like to test NN model with keras using a dataset containing positive and negative continuous values. The keras model is as follows: Everything seem going fine, However, all the negative values are predicted to zeros. Do the program soemwhere constrains values to be positive? My target values are as follow: The predicted values are as follow:"
Training Bug,69284837,"wEncoder = torch.randn(D,1, requires_grad=True) wDecoder = torch.randn(1,D, requires_grad=True) bEncoder = torch.randn(1, requires_grad=True) bDecoder = torch.randn(1,D, requires_grad=True) D = 2 x = torch.rand(100,D) x[:,0] = x[:,0] + x[:,1] x[:,1] = 0.5*x[:,0] + x[:,1] loss_fn = nn.MSELoss() optimizer = optim.SGD([x[:,0],x[:,1]], lr=0.01) losses = [] for epoch in range(1000): running_loss = 0.0 inputs = x_reconstructed targets = x loss=loss_fn(inputs,targets) loss.backward(retain_graph=True) optimizer.step() optimizer.zero_grad() running_loss += loss.item() epoch_loss = running_loss / len(data) losses.append(running_loss)","How do we build a simple linear autoencoder and train it using torch.optim optimisers? How do I do it using autograd (.backward()) and optimising the MSE loss, and then learn the values of the weights and biases in the encoder, and the decoder (ie. 3 parameters in the encoder and 4 in the decoder)? And the data has to be randomized, for each run of learning, start from random weights and biases, such as: The target optimizer is SGD, learning rate 0.01, no momentum, and 1000 steps (from a random start), then how do we plot loss versus epochs (steps)? I tried this but the losses are the same for every epoch."
