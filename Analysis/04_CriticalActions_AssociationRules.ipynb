{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from apyori import apriori\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Dataset/Dataset_CriticalActions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Training Bug with value T, Model bug with value M, API bug with value A, Tensor & Input Bug with value I, and GPU Bug with value G\n",
    "df.loc[df['Type of Bug'] == 'Training Bug', 'Type of Bug'] = 'T'\n",
    "df.loc[df['Type of Bug'] == 'Model Bug', 'Type of Bug'] = 'M'\n",
    "df.loc[df['Type of Bug'] == 'API Bug', 'Type of Bug'] = 'A'\n",
    "df.loc[df['Type of Bug'] == 'Tensor and Input Bug', 'Type of Bug'] = 'I'\n",
    "df.loc[df['Type of Bug'] == 'GPU Bug', 'Type of Bug'] = 'G'\n",
    "df.loc[df['Type of Bug'] == 'Mixed Bug', 'Type of Bug'] = 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all 1's with the corresponding letter\n",
    "df['Data'] = df['Data'].replace(1, 'D')\n",
    "df['Neural Network'] = df['Neural Network'].replace(1, 'N')\n",
    "df['Logs'] = df['Logs'].replace(1, 'L')\n",
    "df['Hyperparameters'] = df['Hyperparameters'].replace(1, 'H')\n",
    "df['Training Code'] = df['Training Code'].replace(1, 'C')\n",
    "\n",
    "\n",
    "df['Data'] = df['Data'].replace(0, '')\n",
    "df['Neural Network'] = df['Neural Network'].replace(0, '')\n",
    "df['Logs'] = df['Logs'].replace(0, '')\n",
    "df['Hyperparameters'] = df['Hyperparameters'].replace(0, '')\n",
    "df['Training Code'] = df['Training Code'].replace(0, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_bugs = df[df['Type of Bug'] == 'T']\n",
    "gpu_bugs = df[df['Type of Bug'] == 'G']\n",
    "api_bugs = df[df['Type of Bug'] == 'A']\n",
    "model_bugs = df[df['Type of Bug'] == 'M']\n",
    "tensor_bugs = df[df['Type of Bug'] == 'I']\n",
    "mixed_bugs = df[df['Type of Bug'] == 'X']\n",
    "\n",
    "training_transactions = []\n",
    "for i in range(0, len(training_bugs)):\n",
    "    training_transactions.append([str(training_bugs.values[i,j]) for j in range(0, len(training_bugs.columns)) if str(training_bugs.values[i,j]) != ''])\n",
    "\n",
    "gpu_transactions = []\n",
    "for i in range(0, len(gpu_bugs)):\n",
    "    gpu_transactions.append([str(gpu_bugs.values[i,j]) for j in range(0, len(gpu_bugs.columns)) if str(gpu_bugs.values[i,j]) != ''])\n",
    "\n",
    "api_transactions = []\n",
    "for i in range(0, len(api_bugs)):\n",
    "    api_transactions.append([str(api_bugs.values[i,j]) for j in range(0, len(api_bugs.columns)) if str(api_bugs.values[i,j]) != ''])\n",
    "\n",
    "model_transactions = []\n",
    "for i in range(0, len(model_bugs)):\n",
    "    model_transactions.append([str(model_bugs.values[i,j]) for j in range(0, len(model_bugs.columns)) if str(model_bugs.values[i,j]) != ''])\n",
    "\n",
    "tensor_transactions = []\n",
    "for i in range(0, len(tensor_bugs)):\n",
    "    tensor_transactions.append([str(tensor_bugs.values[i,j]) for j in range(0, len(tensor_bugs.columns)) if str(tensor_bugs.values[i,j]) != ''])\n",
    "\n",
    "mixed_transactions = []\n",
    "for i in range(0, len(mixed_bugs)):\n",
    "    mixed_transactions.append([str(mixed_bugs.values[i,j]) for j in range(0, len(mixed_bugs.columns)) if str(mixed_bugs.values[i,j]) != ''])\n",
    "\n",
    "transactions = []\n",
    "for i in range(0, len(df)):\n",
    "    transactions.append([str(df.values[i,j]) for j in range(0, len(df.columns)) if str(df.values[i,j]) != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "github_transactions = '../Dataset/Dataset_Github_CriticalInformation.csv'\n",
    "\n",
    "# Column headers that should be considered for the dynamic output\n",
    "considered_columns = ['D', 'N', 'H', 'L', 'C']\n",
    "\n",
    "# Function to process the CSV file and extract transactions dynamically\n",
    "def process_csv(file_path):\n",
    "    transactions = []\n",
    "    \n",
    "    with open(file_path, mode='r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        # Iterate over each row in the CSV\n",
    "        for row in reader:\n",
    "            # Collect the columns marked as '1'\n",
    "            marked_columns = [col for col in considered_columns if row[col] == '1']\n",
    "            \n",
    "            # Check if there are any marked columns for this row\n",
    "            if marked_columns:\n",
    "                if row['type'] == 'Training':\n",
    "                    transaction = ['T'] + marked_columns\n",
    "                    training_transactions.append(transaction)\n",
    "                elif row['type'] == 'GPU':\n",
    "                    transaction = ['G'] + marked_columns\n",
    "                    gpu_transactions.append(transaction)\n",
    "                elif row['type'] == 'API':\n",
    "                    transaction = ['A'] + marked_columns\n",
    "                    api_transactions.append(transaction)\n",
    "                elif row['type'] == 'Model':\n",
    "                    transaction = ['M'] + marked_columns\n",
    "                    model_transactions.append(transaction)\n",
    "                elif row['type'] == 'Tensor and Input':\n",
    "                    transaction = ['I'] + marked_columns\n",
    "                    tensor_transactions.append(transaction)\n",
    "\n",
    "process_csv(github_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apriori_results(rules, character):\n",
    "    for result in list(rules):\n",
    "     if character in result.items:\n",
    "        items = \", \".join(result.items)\n",
    "        support = result.support\n",
    "        print(f\"Items: {{{items}}}\")\n",
    "        print(f\"Support: {support:.4f}\")\n",
    "        if result.ordered_statistics:\n",
    "            print(\"Association Rules:\")\n",
    "            for rule in result.ordered_statistics:\n",
    "                if character in rule.items_base:\n",
    "                    antecedent = \", \".join(rule.items_base)\n",
    "                    consequent = \", \".join(rule.items_add)\n",
    "                    confidence = rule.confidence\n",
    "                    lift = rule.lift\n",
    "                    print(f\"  {{{antecedent}}} => {{{consequent}}}\")\n",
    "                    print(f\"Confidence: {confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: {T}\n",
      "Support: 1.0000\n",
      "Association Rules:\n",
      "Items: {T, C}\n",
      "Support: 0.8600\n",
      "Association Rules:\n",
      "  {T} => {C}\n",
      "Confidence: 0.8600\n",
      "Items: {T, D}\n",
      "Support: 0.8200\n",
      "Association Rules:\n",
      "  {T} => {D}\n",
      "Confidence: 0.8200\n",
      "Items: {H, T}\n",
      "Support: 0.7200\n",
      "Association Rules:\n",
      "  {T} => {H}\n",
      "Confidence: 0.7200\n",
      "Items: {T, L}\n",
      "Support: 0.7600\n",
      "Association Rules:\n",
      "  {T} => {L}\n",
      "Confidence: 0.7600\n",
      "Items: {N, T}\n",
      "Support: 0.5800\n",
      "Association Rules:\n",
      "  {T} => {N}\n",
      "Confidence: 0.5800\n"
     ]
    }
   ],
   "source": [
    "get_apriori_results(apriori(training_transactions, max_length = 2), 'T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: {M}\n",
      "Support: 1.0000\n",
      "Association Rules:\n",
      "Items: {M, C}\n",
      "Support: 0.7143\n",
      "Association Rules:\n",
      "  {M} => {C}\n",
      "Confidence: 0.7143\n",
      "Items: {M, D}\n",
      "Support: 0.5476\n",
      "Association Rules:\n",
      "  {M} => {D}\n",
      "Confidence: 0.5476\n",
      "Items: {H, M}\n",
      "Support: 0.6429\n",
      "Association Rules:\n",
      "  {M} => {H}\n",
      "Confidence: 0.6429\n",
      "Items: {M, L}\n",
      "Support: 0.7857\n",
      "Association Rules:\n",
      "  {M} => {L}\n",
      "Confidence: 0.7857\n",
      "Items: {M, N}\n",
      "Support: 0.6429\n",
      "Association Rules:\n",
      "  {M} => {N}\n",
      "Confidence: 0.6429\n"
     ]
    }
   ],
   "source": [
    "get_apriori_results(apriori(model_transactions, max_length = 2), 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: {G}\n",
      "Support: 1.0000\n",
      "Association Rules:\n",
      "Items: {G, C}\n",
      "Support: 0.6667\n",
      "Association Rules:\n",
      "  {G} => {C}\n",
      "Confidence: 0.6667\n",
      "Items: {G, L}\n",
      "Support: 1.0000\n",
      "Association Rules:\n",
      "  {G} => {L}\n",
      "Confidence: 1.0000\n"
     ]
    }
   ],
   "source": [
    "get_apriori_results(apriori(gpu_transactions, max_length = 2), 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: {I}\n",
      "Support: 1.0000\n",
      "Association Rules:\n",
      "Items: {I, C}\n",
      "Support: 0.7241\n",
      "Association Rules:\n",
      "  {I} => {C}\n",
      "Confidence: 0.7241\n",
      "Items: {I, D}\n",
      "Support: 0.9655\n",
      "Association Rules:\n",
      "  {I} => {D}\n",
      "Confidence: 0.9655\n",
      "Items: {H, I}\n",
      "Support: 0.4138\n",
      "Association Rules:\n",
      "  {I} => {H}\n",
      "Confidence: 0.4138\n",
      "Items: {I, L}\n",
      "Support: 0.9310\n",
      "Association Rules:\n",
      "  {I} => {L}\n",
      "Confidence: 0.9310\n",
      "Items: {I, N}\n",
      "Support: 0.5172\n",
      "Association Rules:\n",
      "  {I} => {N}\n",
      "Confidence: 0.5172\n"
     ]
    }
   ],
   "source": [
    "get_apriori_results(apriori(tensor_transactions, max_length = 2), 'I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: {A}\n",
      "Support: 1.0000\n",
      "Association Rules:\n",
      "Items: {A, C}\n",
      "Support: 0.7500\n",
      "Association Rules:\n",
      "  {A} => {C}\n",
      "Confidence: 0.7500\n",
      "Items: {A, D}\n",
      "Support: 0.5500\n",
      "Association Rules:\n",
      "  {A} => {D}\n",
      "Confidence: 0.5500\n",
      "Items: {H, A}\n",
      "Support: 0.2500\n",
      "Association Rules:\n",
      "  {A} => {H}\n",
      "Confidence: 0.2500\n",
      "Items: {A, L}\n",
      "Support: 0.8500\n",
      "Association Rules:\n",
      "  {A} => {L}\n",
      "Confidence: 0.8500\n",
      "Items: {N, A}\n",
      "Support: 0.7000\n",
      "Association Rules:\n",
      "  {A} => {N}\n",
      "Confidence: 0.7000\n"
     ]
    }
   ],
   "source": [
    "get_apriori_results(apriori(api_transactions, max_length = 2), 'A')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
